# å¤šå¸§æ¨¡å‹çš„å›¾åƒå¯è§†åŒ–

import cv2
import numpy as np
from PIL import Image

from vid_map_coco import get_history_imgs
import colorsys
import os
import time

import numpy as np
import torch
import torch.nn as nn
from PIL import ImageDraw, ImageFont

from nets.TASA import Tasanet

from utils.utils import (cvtColor, get_classes, preprocess_input, resize_image,
                         show_config)
from utils.utils_bbox import decode_outputs, non_max_suppression

class Pred_vid(object):
    _defaults = {
        #--------------------------------------------------------------------------#
        #   ä½¿ç”¨è‡ªå·±è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹ä¸€å®šè¦ä¿®æ”¹model_pathå’Œclasses_pathï¼
        #   model_pathæŒ‡å‘logsæ–‡ä»¶å¤¹ä¸‹çš„æƒå€¼æ–‡ä»¶ï¼Œclasses_pathæŒ‡å‘model_dataä¸‹çš„txt
        #
        #   è®­ç»ƒå¥½ålogsæ–‡ä»¶å¤¹ä¸‹å­˜åœ¨å¤šä¸ªæƒå€¼æ–‡ä»¶ï¼Œé€‰æ‹©éªŒè¯é›†æŸå¤±è¾ƒä½çš„å³å¯ã€‚
        #   éªŒè¯é›†æŸå¤±è¾ƒä½ä¸ä»£è¡¨mAPè¾ƒé«˜ï¼Œä»…ä»£è¡¨è¯¥æƒå€¼åœ¨éªŒè¯é›†ä¸Šæ³›åŒ–æ€§èƒ½è¾ƒå¥½ã€‚
        #   å¦‚æœå‡ºç°shapeä¸åŒ¹é…ï¼ŒåŒæ—¶è¦æ³¨æ„è®­ç»ƒæ—¶çš„model_pathå’Œclasses_pathå‚æ•°çš„ä¿®æ”¹
        #--------------------------------------------------------------------------#
        "model_path"        : 'D:/affair/college/ISTD/TMP/logs/loss_2025_12_11_11_26_21/best_epoch_weights.pth',
        "classes_path"      : 'D:/affair/college/ISTD/TMP/model_data/classes.txt',
        #---------------------------------------------------------------------#
        #   è¾“å…¥å›¾ç‰‡çš„å¤§å°ï¼Œå¿…é¡»ä¸º32çš„å€æ•°ã€‚
        #---------------------------------------------------------------------#
        "input_shape"       : [512, 512],
        #---------------------------------------------------------------------#
        #   æ‰€ä½¿ç”¨çš„YoloXçš„ç‰ˆæœ¬ã€‚nanoã€tinyã€sã€mã€lã€x
        #---------------------------------------------------------------------#
        "phi"               : 's',
        #---------------------------------------------------------------------#
        #   åªæœ‰å¾—åˆ†å¤§äºç½®ä¿¡åº¦çš„é¢„æµ‹æ¡†ä¼šè¢«ä¿ç•™ä¸‹æ¥
        #---------------------------------------------------------------------#
        "confidence"        : 0.5,
        #---------------------------------------------------------------------#
        #   éæå¤§æŠ‘åˆ¶æ‰€ç”¨åˆ°çš„nms_iouå¤§å°
        #---------------------------------------------------------------------#
        "nms_iou"           : 0.3,
        #---------------------------------------------------------------------#
        #   è¯¥å˜é‡ç”¨äºæ§åˆ¶æ˜¯å¦ä½¿ç”¨letterbox_imageå¯¹è¾“å…¥å›¾åƒè¿›è¡Œä¸å¤±çœŸçš„resizeï¼Œ
        #   åœ¨å¤šæ¬¡æµ‹è¯•åï¼Œå‘ç°å…³é—­letterbox_imageç›´æ¥resizeçš„æ•ˆæœæ›´å¥½
        #---------------------------------------------------------------------#
        "letterbox_image"   : True,
        #-------------------------------#
        #   æ˜¯å¦ä½¿ç”¨Cuda
        #   æ²¡æœ‰GPUå¯ä»¥è®¾ç½®æˆFalse
        #-------------------------------#
        "cuda"              : False,
    }

    @classmethod
    def get_defaults(cls, n):
        if n in cls._defaults:
            return cls._defaults[n]
        else:
            return "Unrecognized attribute name '" + n + "'"

    #---------------------------------------------------#
    #   åˆå§‹åŒ–
    #---------------------------------------------------#
    def __init__(self, **kwargs):
        self.__dict__.update(self._defaults)
        for name, value in kwargs.items():
            setattr(self, name, value)
            
        #---------------------------------------------------#
        #   è·å¾—ç§ç±»å’Œå…ˆéªŒæ¡†çš„æ•°é‡
        #---------------------------------------------------#
        self.class_names, self.num_classes  = get_classes(self.classes_path)

        #---------------------------------------------------#
        #   ç”»æ¡†è®¾ç½®ä¸åŒçš„é¢œè‰²
        #---------------------------------------------------#
        hsv_tuples = [(x / self.num_classes, 1., 1.) for x in range(self.num_classes)]
        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))
        self.colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), self.colors))
        self.generate()
        
        show_config(**self._defaults)

    #---------------------------------------------------#
    #   ç”Ÿæˆæ¨¡å‹
    #---------------------------------------------------#
    def generate(self, onnx=False):
        self.net    = Tasanet(self.num_classes, num_frame=5)
        device      = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.net.load_state_dict(torch.load(self.model_path, map_location=device))
        self.net    = self.net.eval()
        print('{} model, and classes loaded.'.format(self.model_path))
        if not onnx:
            if self.cuda:
                self.net = nn.DataParallel(self.net)
                self.net = self.net.cuda()
                
     #---------------------------------------------------#
    #   æ£€æµ‹å›¾ç‰‡
    #---------------------------------------------------#
    def detect_image(self, images, crop = False, count = False):
        #---------------------------------------------------#
        #   è®¡ç®—è¾“å…¥å›¾ç‰‡çš„é«˜å’Œå®½
        #---------------------------------------------------#
        image_shape = np.array(np.shape(images[0])[0:2])
        #---------------------------------------------------------#
        #   åœ¨è¿™é‡Œå°†å›¾åƒè½¬æ¢æˆRGBå›¾åƒï¼Œé˜²æ­¢ç°åº¦å›¾åœ¨é¢„æµ‹æ—¶æŠ¥é”™ã€‚
        #   ä»£ç ä»…ä»…æ”¯æŒRGBå›¾åƒçš„é¢„æµ‹ï¼Œæ‰€æœ‰å…¶å®ƒç±»å‹çš„å›¾åƒéƒ½ä¼šè½¬åŒ–æˆRGB
        #---------------------------------------------------------#
        images       = [cvtColor(image) for image in images]
        c_image = images[-1]
        #---------------------------------------------------------#
        #   ç»™å›¾åƒå¢åŠ ç°æ¡ï¼Œå®ç°ä¸å¤±çœŸçš„resize
        #   ä¹Ÿå¯ä»¥ç›´æ¥resizeè¿›è¡Œè¯†åˆ«
        #---------------------------------------------------------#
        image_data  = [resize_image(image, (self.input_shape[1],self.input_shape[0]), self.letterbox_image) for image in images]
        #---------------------------------------------------------#
        #   æ·»åŠ ä¸Šbatch_sizeç»´åº¦
        #---------------------------------------------------------#
        image_data = [np.transpose(preprocess_input(np.array(image, dtype='float32')), (2, 0, 1)) for image in image_data]
        # (3, 640, 640) -> (3, 16, 640, 640)
        image_data = np.stack(image_data, axis=1)
        
        image_data  = np.expand_dims(image_data, 0)

        with torch.no_grad():
            images = torch.from_numpy(image_data)
            if self.cuda:
                images = images.cuda()
            #---------------------------------------------------------#
            #   å°†å›¾åƒè¾“å…¥ç½‘ç»œå½“ä¸­è¿›è¡Œé¢„æµ‹ï¼
            #---------------------------------------------------------#
            outputs = self.net(images)
            outputs = decode_outputs(outputs, self.input_shape)
            #---------------------------------------------------------#
            #   å°†é¢„æµ‹æ¡†è¿›è¡Œå †å ï¼Œç„¶åè¿›è¡Œéæå¤§æŠ‘åˆ¶
            #---------------------------------------------------------#
            outputs = non_max_suppression(outputs, self.num_classes, self.input_shape, 
                        image_shape, self.letterbox_image, conf_thres = self.confidence, nms_thres = self.nms_iou)
                                                    
            if outputs[0] is None: 
                return c_image

            top_label   = np.array(outputs[0][:, 6], dtype = 'int32')
            top_conf    = outputs[0][:, 4] * outputs[0][:, 5]
            top_boxes   = outputs[0][:, :4]

        #---------------------------------------------------------#
        #   è®¾ç½®å­—ä½“ä¸è¾¹æ¡†åšåº¦
        #---------------------------------------------------------#
        font        = ImageFont.truetype(font='model_data/simhei.ttf', size=np.floor(3e-2 * c_image.size[1] + 15).astype('int32'))  #######
        thickness   = int(max((c_image.size[0] + c_image.size[1]) // np.mean(self.input_shape), 1))
        #---------------------------------------------------------#
        #   è®¡æ•°
        #---------------------------------------------------------#
        if count:
            print("top_label:", top_label)
            classes_nums    = np.zeros([self.num_classes])
            for i in range(self.num_classes):
                num = np.sum(top_label == i)
                if num > 0:
                    print(self.class_names[i], " : ", num)
                classes_nums[i] = num
            print("classes_nums:", classes_nums)
        #---------------------------------------------------------#
        #   æ˜¯å¦è¿›è¡Œç›®æ ‡çš„è£å‰ª
        #---------------------------------------------------------#
        if crop:
            for i, c in list(enumerate(top_label)):
                top, left, bottom, right = top_boxes[i]
                top     = max(0, np.floor(top).astype('int32'))
                left    = max(0, np.floor(left).astype('int32'))
                bottom  = min(c_image.size[1], np.floor(bottom).astype('int32'))
                right   = min(c_image.size[0], np.floor(right).astype('int32'))
                
                # dir_save_path = "img_crop"
                dir_save_path =os.path.join(r'D:\affair\college\ISTD\TMP\output', "img_crop")
                if not os.path.exists(dir_save_path):
                    os.makedirs(dir_save_path)
                crop_image = c_image.crop([left, top, right, bottom])
                crop_image.save(os.path.join(dir_save_path, "crop_" + str(i) + ".png"), quality=95, subsampling=0)
                print("save crop_" + str(i) + ".png to " + dir_save_path)

        #---------------------------------------------------------#
        #   å›¾åƒç»˜åˆ¶
        #---------------------------------------------------------#
        for i, c in list(enumerate(top_label)):
            predicted_class = self.class_names[int(c)]
            box             = top_boxes[i]
            score           = top_conf[i]

            top, left, bottom, right = box

            top     = max(0, np.floor(top).astype('int32'))
            left    = max(0, np.floor(left).astype('int32'))
            bottom  = min(c_image.size[1], np.floor(bottom).astype('int32'))
            right   = min(c_image.size[0], np.floor(right).astype('int32'))

            label = '{} {:.2f}'.format(predicted_class, score)
            draw = ImageDraw.Draw(c_image)
            # label_size = draw.textsize(label, font)
            label_size = draw.textbbox((125, 20),label, font)
            label = label.encode('utf-8')
            # print(label, top, left, bottom, right)
            
            if top - label_size[1] >= 0:
                text_origin = np.array([left, top - label_size[1]])
            else:
                text_origin = np.array([left, top + 1])

            for i in range(thickness):
                draw.rectangle([left + i, top + i, right - i, bottom - i], outline=self.colors[c])
            # draw.rectangle([tuple(text_origin), tuple(text_origin + label_size[:2])], fill=self.colors[c])
            # draw.rectangle([tuple(text_origin), tuple(text_origin)], fill=self.colors[c])
            # draw.text(text_origin, str(label,'UTF-8'), fill=(0, 0, 0), font=font)
            del draw

        return c_image
    
if __name__ == "__main__":
    yolo = Pred_vid()
    #----------------------------------------------------------------------------------------------------------#
    #   modeç”¨äºæŒ‡å®šæµ‹è¯•çš„æ¨¡å¼ï¼š
    #   'predict'           è¡¨ç¤ºå•å¼ å›¾ç‰‡é¢„æµ‹ï¼Œå¦‚æœæƒ³å¯¹é¢„æµ‹è¿‡ç¨‹è¿›è¡Œä¿®æ”¹ï¼Œå¦‚ä¿å­˜å›¾ç‰‡ï¼Œæˆªå–å¯¹è±¡ç­‰ï¼Œå¯ä»¥å…ˆçœ‹ä¸‹æ–¹è¯¦ç»†çš„æ³¨é‡Š
    #   'video'             è¡¨ç¤ºåºåˆ—å›¾ç‰‡é¢„æµ‹ï¼Œè¾“å‡ºä¸ºè§†é¢‘
    #----------------------------------------------------------------------------------------------------------#
    mode = "video"
    #-------------------------------------------------------------------------#
    #   crop                æŒ‡å®šäº†æ˜¯å¦åœ¨å•å¼ å›¾ç‰‡é¢„æµ‹åå¯¹ç›®æ ‡è¿›è¡Œæˆªå–
    #   count               æŒ‡å®šäº†æ˜¯å¦è¿›è¡Œç›®æ ‡çš„è®¡æ•°
    #   cropã€countä»…åœ¨mode='predict'æ—¶æœ‰æ•ˆ
    #-------------------------------------------------------------------------#
    crop            = False
    count           = False
    #----------------------------------------------------------------------------------------------------------#


    if mode == "predict":
        '''
        1ã€å¦‚æœæƒ³è¦è¿›è¡Œæ£€æµ‹å®Œçš„å›¾ç‰‡çš„ä¿å­˜ï¼Œåˆ©ç”¨r_image.save("img.jpg")å³å¯ä¿å­˜ï¼Œç›´æ¥åœ¨predict.pyé‡Œè¿›è¡Œä¿®æ”¹å³å¯ã€‚ 
        2ã€å¦‚æœæƒ³è¦è·å¾—é¢„æµ‹æ¡†çš„åæ ‡ï¼Œå¯ä»¥è¿›å…¥yolo.detect_imageå‡½æ•°ï¼Œåœ¨ç»˜å›¾éƒ¨åˆ†è¯»å–topï¼Œleftï¼Œbottomï¼Œrightè¿™å››ä¸ªå€¼ã€‚
        3ã€å¦‚æœæƒ³è¦åˆ©ç”¨é¢„æµ‹æ¡†æˆªå–ä¸‹ç›®æ ‡ï¼Œå¯ä»¥è¿›å…¥yolo.detect_imageå‡½æ•°ï¼Œåœ¨ç»˜å›¾éƒ¨åˆ†åˆ©ç”¨è·å–åˆ°çš„topï¼Œleftï¼Œbottomï¼Œrightè¿™å››ä¸ªå€¼
        åœ¨åŸå›¾ä¸Šåˆ©ç”¨çŸ©é˜µçš„æ–¹å¼è¿›è¡Œæˆªå–ã€‚
        4ã€å¦‚æœæƒ³è¦åœ¨é¢„æµ‹å›¾ä¸Šå†™é¢å¤–çš„å­—ï¼Œæ¯”å¦‚æ£€æµ‹åˆ°çš„ç‰¹å®šç›®æ ‡çš„æ•°é‡ï¼Œå¯ä»¥è¿›å…¥yolo.detect_imageå‡½æ•°ï¼Œåœ¨ç»˜å›¾éƒ¨åˆ†å¯¹predicted_classè¿›è¡Œåˆ¤æ–­ï¼Œ
        æ¯”å¦‚åˆ¤æ–­if predicted_class == 'car': å³å¯åˆ¤æ–­å½“å‰ç›®æ ‡æ˜¯å¦ä¸ºè½¦ï¼Œç„¶åè®°å½•æ•°é‡å³å¯ã€‚åˆ©ç”¨draw.textå³å¯å†™å­—ã€‚
        '''
        # while True:
            # img = input('Input image filename:')
        img = 'D:\\affair\\college\\ISTD\\TMP\\DAUB\\images\\test\\data6\\364.bmp'
        try:
            img = get_history_imgs(img)
            images = [Image.open(item) for item in img]
        except:
            print('Open Error! Try again!')
        else:
            r_image = yolo.detect_image(images, crop = crop, count=count)
            output_dir = r'D:\affair\college\ISTD\TMP\output'
            os.makedirs(output_dir, exist_ok=True)
            output_image_path = os.path.join(output_dir, "Our_68_100.jpg") # ä¿æŒåŸæ–‡ä»¶å
            r_image.save("Our_68_100.jpg")
            print("Detect finish.")
    elif mode == "video":
        import numpy as np
        from tqdm import tqdm
        dir_path = 'D:\\affair\\college\\ISTD\\TMP\\DAUB\\images\\test\\data6'
        output_dir = r'D:\affair\college\ISTD\TMP\output'
        os.makedirs(output_dir, exist_ok=True) 
        output_video_path = os.path.join(output_dir, "output.avi")
        images = os.listdir(dir_path)
        images.sort(key=lambda x:int(x[:-4]))
        list_img = []
        # for image in tqdm(images):
        #     image = dir_path+image
        #     img = get_history_imgs(image)
        #     imgs = [Image.open(item) for item in img]
        #     r_image = yolo.detect_image(imgs, crop = crop, count=count)
        #     list_img.append(cv2.cvtColor(np.asarray(r_image), cv2.COLOR_RGB2BGR))
        for image_name in tqdm(images):
            # -------------------------------------------------------------
            # ğŸŒŸ ä¿®å¤ç‚¹ 2 (å…³é”®): ä½¿ç”¨ os.path.join() æ­£ç¡®æ‹¼æ¥è·¯å¾„
            # -------------------------------------------------------------
            image_full_path = os.path.join(dir_path, image_name)
            
            # ä½¿ç”¨æ­£ç¡®çš„å®Œæ•´è·¯å¾„è°ƒç”¨ get_history_imgs
            img_paths = get_history_imgs(image_full_path) 
            imgs = [Image.open(item) for item in img_paths]
            r_image = yolo.detect_image(imgs, crop = crop, count=count)
            list_img.append(cv2.cvtColor(np.asarray(r_image), cv2.COLOR_RGB2BGR))
        fourcc = cv2.VideoWriter_fourcc(*'XVID')# *'XVID'           è§†é¢‘ç¼–è§£ç å™¨
        outfile = cv2.VideoWriter("output_video_path", fourcc, 5, (512, 512), True)    #å¤§å°å¿…é¡»å’Œå›¾ç‰‡å¤§å°ä¸€è‡´,ä¸”æ‰€æœ‰å›¾ç‰‡å¤§å°å¿…é¡»ä¸€è‡´   -- photo_resize.py      
        # outfile = cv2.VideoWriter("./output.avi", fourcc, 5, (720, 480), True) 
        for i in list_img: 
            outfile.write(i) # è§†é¢‘æ–‡ä»¶å†™å…¥ä¸€å¸§
            #cv2.imshow('frame', next(img_iter)) 
            if cv2.waitKey(1) == 27: # æŒ‰ä¸‹Escé”®ï¼Œç¨‹åºé€€å‡º(Escçš„ASCIIå€¼æ˜¯27ï¼Œå³0001  1011)
                break 
        outfile.release()
        cv2.destroyAllWindows()

    
    else:
        raise AssertionError("Please specify the correct mode: 'predict', 'video'.")